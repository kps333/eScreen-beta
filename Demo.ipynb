{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e016364-bde6-447d-9107-5c9d71373743",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os,subprocess\n",
    "os.environ['CUDA_HOME'] = \"/cluster2/huanglab/liquan/apps/CUDA/cuda-11.8/lib64\"\n",
    "\n",
    "import genome_tool\n",
    "import miaomiao_tool\n",
    "from motif_tool import load_pwm_from_meme_c,load_pwm_from_meme_c1,CenteredMaxPool1D\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f44177ef-4c38-4c5b-919a-64457eba3d7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from vortex.main.ParallelGatedConvBlock import ParallelGatedConvBlock\n",
    "from vortex.main.AttentionBlock import AttentionBlock\n",
    "from vortex.main.RMSNorm import RMSNorm\n",
    "from vortex.main.HyenaInferenceEngine import fftconv_standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8bb2eca-5fd2-49f0-9455-a00a4de39399",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from einops import rearrange\n",
    "import sys,sqlite3,glob,pickle,copy,json\n",
    "from scipy.stats import spearmanr,pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94610a3-f25d-45f6-a87e-a3bf63eb99bb",
   "metadata": {},
   "source": [
    "# Model Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea67ec8a-0bb3-4048-adaf-e20c554b27cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class eSCREEN(nn.Module):\n",
    "    def __init__(self,kernel_fwd,kernel_rev=None,d_model=32,num_filters=32,seq_length=500,celltype_num=32,mode='sequence',device='cpu',lr=1e-5):\n",
    "        super().__init__()\n",
    "        # 定义模型架构\n",
    "        self.kernel_fwd = kernel_fwd # 正向motif,不可学习\n",
    "        self.kernel_rev = kernel_rev # 逆向motif,不可学习\n",
    "        self.pwm_thresh = nn.Parameter(torch.tensor([0.4])) # 认为是motif的最小阈值,可学习\n",
    "        \n",
    "        self.d_model = d_model # 特征维度数\n",
    "        self.seq_length = seq_length # 最长序列长度\n",
    "        self.celltype_num = celltype_num # 细胞类型数\n",
    "        \n",
    "        self.HyenaCluster=nn.ModuleList([ # Hyena模块簇\n",
    "            self.get_block(\n",
    "                d_model=d_model,layer_idx=0,num_filters=d_model,num_attention_heads=8,hyena_filter_groups=128,fir_inner_filter_length=7,block_type='HyenaSE'\n",
    "            ),\n",
    "            self.get_block(\n",
    "                d_model=d_model,layer_idx=1,num_filters=d_model,num_attention_heads=8,hyena_filter_groups=128,fir_inner_filter_length=128,block_type='HyenaMR'\n",
    "            ),\n",
    "            self.get_block(\n",
    "                d_model=d_model,layer_idx=2,num_filters=d_model,num_attention_heads=8,block_type='HyenaLI'\n",
    "            ),\n",
    "            self.get_block(\n",
    "                d_model=d_model,layer_idx=3,num_attention_heads=8,block_type='Attention'\n",
    "            )\n",
    "        ])\n",
    "        \n",
    "        self.motif_embedding    = nn.Linear(self.kernel_fwd.size(0),d_model) # 编码motif的embeding\n",
    "        self.celltype_embedding = nn.Embedding(num_embeddings=self.celltype_num, embedding_dim=d_model) # 编码celltype的embeding\n",
    "        self.CenterMaxPool = CenteredMaxPool1D(kernel_size=19, stride=1)\n",
    "        \n",
    "        self.header=nn.Sequential(\n",
    "            nn.Linear(d_model*(seq_length+celltype_num),d_model),\n",
    "            nn.BatchNorm1d(d_model),\n",
    "            nn.Linear(d_model,d_model),\n",
    "            nn.BatchNorm1d(d_model),\n",
    "            nn.Linear(d_model,1),\n",
    "        )\n",
    "\n",
    "        self.device=device\n",
    "        \n",
    "    def get_block(self,block_type='HyenaLI',**kwargs):\n",
    "        if block_type=='HyenaSE':\n",
    "            return ParallelGatedConvBlock(\n",
    "                              hidden_size        = kwargs['d_model'],\n",
    "                              layer_idx          = kwargs['layer_idx'],\n",
    "                              qkv_proj_bias      = False,\n",
    "                              hyena_out_proj_bias= True,   \n",
    "                              state_size  = 16,\n",
    "                              num_filters = kwargs['num_filters'], # 注意这个参数不能比hidden_size大\n",
    "                              num_attention_heads= kwargs['num_attention_heads'], # 这个参数和后面的attention层一致即可\n",
    "                              short_filter_length= 3,\n",
    "                              short_filter_bias  = False,\n",
    "                              hyena_filter_groups    = kwargs['hyena_filter_groups'],     # 区分HyenaMR和HyenaSE,不能比d_model更大,需要被d_model整除\n",
    "                              fir_inner_filter_length= kwargs['fir_inner_filter_length'], # 参数是区分HyenaMR和HyenaSE的关键\n",
    "                              inner_size_multiple_of = 16,      # 这五个参数是MLP的参数\n",
    "                              mlp_activation         = 'gelu',  # 这五个参数是MLP的参数\n",
    "                              evo2_style_activations = True,    # 这五个参数是MLP的参数\n",
    "                              model_parallel_size    = 1,       # 这五个参数是MLP的参数\n",
    "                              inner_mlp_size         = 256,     # 这五个参数是MLP的参数\n",
    "                              column_split_hyena     = False, # 这个是HyenaCascade的参数\n",
    "                              interleave             = True,  # 这个是HyenaCascade的参数\n",
    "                              hyena_flip_x1x2        = False, # 这个是HyenaCascade的参数\n",
    "                              use_flash_depthwise    = False, # 这个是HyenaCascade的参数\n",
    "                              use_flashfft           = False, # 这个是HyenaCascade的参数\n",
    "                              prefill_style          = 'fft', # 这个是HyenaCascade的参数\n",
    "                              bidirectional          = True   # 这个是HyenaCascade的参数\n",
    "            ).to(torch.bfloat16)\n",
    "        elif block_type=='HyenaMR':\n",
    "            return ParallelGatedConvBlock(\n",
    "                              hidden_size= kwargs['d_model'],\n",
    "                              layer_idx  = kwargs['layer_idx'],\n",
    "                              qkv_proj_bias=False,\n",
    "                              hyena_out_proj_bias=True,\n",
    "                              state_size = 16,\n",
    "                              num_filters= kwargs['num_filters'],\n",
    "                              num_attention_heads    = kwargs['num_attention_heads'], # 这个参数和后面的attention层一致即可\n",
    "                              short_filter_length    = 3,\n",
    "                              short_filter_bias      = False,\n",
    "                              hyena_filter_groups    = kwargs['hyena_filter_groups'],     # 区分HyenaMR和HyenaSE,不能比d_model更大,需要被d_model整除\n",
    "                              fir_inner_filter_length= kwargs['fir_inner_filter_length'], # 参数是区分HyenaMR和HyenaSE的关键\n",
    "                              inner_size_multiple_of = 16,     # 这五个参数是MLP的参数\n",
    "                              mlp_activation         = 'gelu', # 这五个参数是MLP的参数\n",
    "                              evo2_style_activations = True,   # 这五个参数是MLP的参数\n",
    "                              model_parallel_size    = 1,      # 这五个参数是MLP的参数\n",
    "                              inner_mlp_size         = 256,    # 这五个参数是MLP的参数\n",
    "                              column_split_hyena     = False, # 这个是HyenaCascade的参数\n",
    "                              interleave             = True,  # 这个是HyenaCascade的参数\n",
    "                              hyena_flip_x1x2        = False, # 这个是HyenaCascade的参数\n",
    "                              use_flash_depthwise    = False, # 这个是HyenaCascade的参数\n",
    "                              use_flashfft           = False, # 这个是HyenaCascade的参数\n",
    "                              prefill_style          = 'fft', # 这个是HyenaCascade的参数\n",
    "                              bidirectional          = True   # 这个是HyenaCascade的参数\n",
    "            ).to(torch.bfloat16)\n",
    "        elif block_type=='HyenaLI':\n",
    "            return ParallelGatedConvBlock(\n",
    "                              hidden_size= kwargs['d_model'],\n",
    "                              layer_idx  = kwargs['layer_idx'],\n",
    "                              qkv_proj_bias=False,\n",
    "                              hyena_out_proj_bias=True,\n",
    "                              state_size = 16,\n",
    "                              num_filters= kwargs['num_filters'],\n",
    "                              num_attention_heads= kwargs['num_attention_heads'], # 这个参数和后面的attention层一致即可\n",
    "                              short_filter_length= 3,\n",
    "                              short_filter_bias  = False,\n",
    "                              proj_groups        = 1,\n",
    "                              # 没有hyena_filter_groups和fir_inner_filter_length两个参数时就变为HyenaLI\n",
    "                              # 原来的配置里use_flashfft=False,所以这里也不传递快速卷积模块\n",
    "                              inner_size_multiple_of =16,     # 这五个参数是MLP的参数\n",
    "                              mlp_activation         ='gelu', # 这五个参数是MLP的参数\n",
    "                              evo2_style_activations =True,   # 这五个参数是MLP的参数\n",
    "                              model_parallel_size    =1,      # 这五个参数是MLP的参数\n",
    "                              inner_mlp_size         =256,    # 这五个参数是MLP的参数\n",
    "                              column_split_hyena     = False, # 这个是HyenaCascade的参数\n",
    "                              interleave             = True,  # 这个是HyenaCascade的参数\n",
    "                              hyena_flip_x1x2        = False, # 这个是HyenaCascade的参数\n",
    "                              use_flash_depthwise    = False, # 这个是HyenaCascade的参数\n",
    "                              use_flashfft           = False, # 这个是HyenaCascade的参数\n",
    "                              prefill_style          = 'fft', # 这个是HyenaCascade的参数\n",
    "                              bidirectional          = True   # 这个是HyenaCascade的参数\n",
    "            ).to(torch.bfloat16)\n",
    "        elif block_type=='Attention':\n",
    "            return AttentionBlock(\n",
    "                              hidden_size        = kwargs['d_model'],\n",
    "                              num_attention_heads= kwargs['num_attention_heads'],\n",
    "                              layer_idx          = kwargs['layer_idx'],\n",
    "                              mha_out_proj_bias  = True,\n",
    "                              qkv_proj_bias      = False,\n",
    "                              use_flash_attn     = False,      # 因为cuda的问题(不支持CUDA 12.4),这里不能用flash attention\n",
    "                              inner_size_multiple_of = 16,     # 这五个参数是MLP的参数\n",
    "                              mlp_activation         = 'gelu', # 这五个参数是MLP的参数\n",
    "                              evo2_style_activations = True,   # 这五个参数是MLP的参数\n",
    "                              model_parallel_size    = 1,      # 这五个参数是MLP的参数\n",
    "                              inner_mlp_size         = 256     # 这五个参数是MLP的参数\n",
    "            ).to(torch.bfloat16)\n",
    "            \n",
    "    def move(self):\n",
    "        self.kernel_fwd = self.kernel_fwd.to(self.device)\n",
    "        self.kernel_rev = self.kernel_rev.to(self.device)\n",
    "        self.pwm_thresh.data = self.pwm_thresh.data.to(self.device)\n",
    "        self.motif_embedding.to(self.device)\n",
    "        self.celltype_embedding.to(self.device)\n",
    "        self.CenterMaxPool.to(self.device)\n",
    "        self.header.to(self.device)\n",
    "        for layer in self.HyenaCluster:\n",
    "            layer.to(self.device)\n",
    "        \n",
    "    def forward(self,x,z):\n",
    "        \n",
    "        ### 扫motif,这个时候的形状从原始的(b,l,4)变为(b,4,l)再变为(b, ck, l)      \n",
    "        x = rearrange( x, 'b l c -> b c l')\n",
    "        if not self.kernel_rev is None:\n",
    "            x = fftconv_standard(signal = x,kernel = self.kernel_fwd,bias=None,padding=17,device = self.device) +\\\n",
    "                fftconv_standard(signal = x,kernel = self.kernel_rev,bias=None,padding=17,device = self.device)\n",
    "        else:\n",
    "            x = fftconv_standard(signal = x,kernel = self.kernel_fwd,bias=None,padding=17,device = self.device)\n",
    "        x = nn.functional.relu(x-self.pwm_thresh)\n",
    "        x = self.CenterMaxPool(x)\n",
    "        x = rearrange( x, 'b c l -> b l c') # 把通道放到最后一个维度\n",
    "        x = self.motif_embedding(x)         # 把特征映射到d_model\n",
    "        z = self.celltype_embedding(z)      # 生成维度为d_model的软嵌入\n",
    "        \n",
    "        x  = torch.concatenate([x,z],dim=1) # 把motif嵌入和软嵌入合在一起,形状变为(batch,ls+lc,d_model)\n",
    "\n",
    "        \n",
    "        ### 通过stripedHyena层和header层,形状维持(batch,ls+lc,d_model)\n",
    "        x = x.to(torch.bfloat16)\n",
    "        for layer in self.HyenaCluster:\n",
    "            x = layer(x)\n",
    "            x = nn.functional.relu(x)\n",
    "            \n",
    "        ### 最后一步展平嵌入进行打分 \n",
    "        x = x.to(torch.float).view(x.size(0),-1)\n",
    "        x = self.header(x).flatten()\n",
    "        x = nn.functional.sigmoid(x)    \n",
    "        return torch.clip(x,0,1)\n",
    "\n",
    "    \n",
    "    def fit(self,train_loader,valid_loader=None,epochs=200,lr=1e-5,check_step=100,earlystop=20,device='cpu',save_name='./torch_logs/best_model'):\n",
    "        \n",
    "        optimizer = torch.optim.Adam(self.parameters(),lr=lr)\n",
    "        self.device = device\n",
    "        best_valid_acc = 0.0; count = 0; best_model = None; valid_count = 0\n",
    "        batch_size = train_loader.batch_size\n",
    "        for epoch in range(epochs):\n",
    "            epoch_loss = 0\n",
    "            for i, batch in enumerate(train_loader):\n",
    "                x,y,z = batch;x = x.to(device);y = y.to(device);z = z.to(device)\n",
    "                self.move();self.train()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                p = self(x,z)\n",
    "\n",
    "                loss = F.binary_cross_entropy(p,y)\n",
    "                #loss = F.mse_loss(p,y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                epoch_loss += loss.item()\n",
    "                \n",
    "                avg_loss = epoch_loss / (i+1)\n",
    "                print(f\"Step/Epoch [{(i+1)*batch_size}/{epoch+1}], Loss: {avg_loss:.4f}\",end='\\r')\n",
    "                \n",
    "                valid_count += 1\n",
    "                if valid_count >= check_step:\n",
    "                    if not valid_loader is None:\n",
    "                        p,y = self.predict(valid_loader,device=device,verbose=True,with_true=True)\n",
    "                        valid_acc    = spearmanr(p,y)[0]\n",
    "                        if valid_acc > best_valid_acc:\n",
    "                            best_valid_acc = valid_acc\n",
    "                            count          = 0\n",
    "                            torch.save(self.state_dict(),save_name+'.best.pt')\n",
    "                            print(f\"Epoch [{epoch+1}], Loss: {avg_loss:.4f}, Val-acc: {valid_acc:.4f} ↑\",end='\\n')\n",
    "                        else:\n",
    "                            count += 1\n",
    "                            print(f\"Epoch [{epoch+1}], Loss: {avg_loss:.4f}, Val-acc: {valid_acc:.4f} -\",end='\\n')\n",
    "                            if count > earlystop:\n",
    "                                print(f'Model early stop in Epoch {epoch+1} with valid Acc {best_valid_acc:.4f}')\n",
    "                                self.load_state_dict(torch.load(save_name+'.best.pt'))\n",
    "                                break\n",
    "                        valid_count = 0\n",
    "                    else:\n",
    "                        print(\"\")\n",
    "                        valid_count = 0\n",
    "        torch.save(self.state_dict(),save_name+'.final.pt')\n",
    "        return None\n",
    "    \n",
    "    def predict(self,data_loader,device='cpu',verbose=True,with_true=False):\n",
    "        y_pred=[];y_true=[];self.eval();self.device=device;self.move()\n",
    "        with torch.no_grad():\n",
    "            if verbose:\n",
    "                for batch in tqdm(data_loader, leave=True):\n",
    "                    if with_true:\n",
    "                        x,y,z = batch;x = x.to(device);y = y.to(device);z = z.to(device)\n",
    "                        preds = self.forward(x,z)\n",
    "                        y_pred.extend(preds.cpu().numpy())\n",
    "                        y_true.extend(y.cpu().numpy())\n",
    "                    else:\n",
    "                        x,y,z = batch;x = x.to(device);z = z.to(device)\n",
    "                        preds = self.forward(x,z)\n",
    "                        y_pred.extend(preds.cpu().numpy())\n",
    "            else:\n",
    "                for batch in data_loader:\n",
    "                    if with_true:\n",
    "                        x,y,z = batch;x = x.to(device);y = y.to(device);z = z.to(device)\n",
    "                        preds = self.forward(x,z)\n",
    "                        y_pred.extend(preds.cpu().numpy())\n",
    "                        y_true.extend(y.cpu().numpy())\n",
    "                    else:\n",
    "                        x,y,z = batch;x = x.to(device);z = z.to(device)\n",
    "                        preds = self.forward(x,z)\n",
    "                        y_pred.extend(preds.cpu().numpy()) \n",
    "                    \n",
    "        return np.array(y_pred),np.array(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747d9f1d-a4a4-48d8-ac5c-b34fea966871",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b13a6ec0-94a2-416f-8490-b780743492e8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400244/400244 [01:04<00:00, 6175.24it/s]\n"
     ]
    }
   ],
   "source": [
    "K562_Demo_Dataset = pd.read_csv('/cluster2/huanglab/liquan/data/eSCREEN/ANLYSIS/code/StripedHyena/dataset/exps146_withreadout.txt',sep='\\t')\n",
    "K562_Demo_Dataset = K562_Demo_Dataset[K562_Demo_Dataset['cell_line']=='K562']\n",
    "K562_Demo_Dataset = K562_Demo_Dataset.groupby(['id','chr','start','end']).agg({'RRA':'max','p':'max'}).reset_index()\n",
    "import pyBigWig as pybw\n",
    "with pybw.open('/cluster2/huanglab/liquan/data/K562/H3K27ac.bigWig') as k27ac,pybw.open('/cluster2/huanglab/liquan/data/K562/DNase.bigWig') as dnase:\n",
    "    for rw in tqdm(K562_Demo_Dataset.itertuples(),total=len(K562_Demo_Dataset)):\n",
    "        K562_Demo_Dataset.at[rw.Index,'dnase']=dnase.stats(rw.chr,rw.start,rw.end,type='mean')[0]\n",
    "        K562_Demo_Dataset.at[rw.Index,'k27ac']=k27ac.stats(rw.chr,rw.start,rw.end,type='mean')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35f2d662-e44f-444f-a069-bd3e64f3395e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster2/huanglab/liquan/temp/Rtemp/ipykernel_4014881/441334972.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pos['label'] = 1\n",
      "/cluster2/huanglab/liquan/temp/Rtemp/ipykernel_4014881/441334972.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pos['cell_type'] = 'K562'\n",
      "Processing sequences: 100%|██████████| 36664/36664 [00:05<00:00, 6375.36it/s] \n",
      "Processing sequences: 100%|██████████| 36664/36664 [00:19<00:00, 1854.22it/s]\n"
     ]
    }
   ],
   "source": [
    "from pyfaidx import Fasta\n",
    "pos = K562_Demo_Dataset[ (K562_Demo_Dataset['RRA']>2) & (K562_Demo_Dataset['p']>2) ]\n",
    "pos['label'] = 1\n",
    "pos['cell_type'] = 'K562'\n",
    "neg = K562_Demo_Dataset[ (K562_Demo_Dataset['RRA']<1) & (K562_Demo_Dataset['p']<1) ].sort_values(by=['dnase','k27ac']).iloc[:len(pos)]\n",
    "neg['label'] = 0\n",
    "neg['cell_type'] = 'K562'\n",
    "table = pd.concat([pos,neg]).reset_index(drop=True)\n",
    "tqdm.pandas(desc=\"Processing sequences\", leave=True)\n",
    "with Fasta('/cluster2/huanglab/liquan/genome_ref/hg38.fa') as hg38:\n",
    "    table['sequence'] = table.progress_apply(lambda x: hg38[x.chr][x.start:x.end].seq.upper(),axis=1)\n",
    "table['one hot'] = table['sequence'].progress_apply(lambda x: genome_tool.one_hot(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4eeaf45-fcbd-4974-b13b-073b3af9a60b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "trainset,testset = train_test_split(table, test_size=0.2, random_state=114514)\n",
    "testset,validset = train_test_split(testset, test_size=0.5, random_state=114514)\n",
    "print(len(trainset),len(testset),len(validset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c36f1db4-5a30-475b-983d-6f7dc05a756f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, df, ct_dict, x_col_name='one hot', y_col_name='label', z_col_name='cell_type', max_len=500):\n",
    "        self.df = df\n",
    "        self.ct_dict = ct_dict\n",
    "        self.x_col_name = x_col_name\n",
    "        self.y_col_name = y_col_name\n",
    "        self.z_col_name = z_col_name\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.df.iloc[idx][self.x_col_name][:self.max_len]\n",
    "        target = self.df.iloc[idx][self.y_col_name]\n",
    "        celltype = self.df.iloc[idx][self.z_col_name]\n",
    "        x = torch.tensor(np.stack(seq), dtype=torch.float)\n",
    "        y = torch.tensor(float(target), dtype=torch.float)\n",
    "        z = torch.tensor(self.ct_dict[celltype],dtype=torch.long)\n",
    "        return x, y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1f79c56-ed80-4db1-bb6f-1d45b58653ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./data/K562_demo_dataset.pkl','rb') as file:\n",
    "    K562_Demo_Dataset = pickle.load(file)\n",
    "    \n",
    "trainset = K562_Demo_Dataset['Trainset']\n",
    "testset  = K562_Demo_Dataset['Testset']\n",
    "validset = K562_Demo_Dataset['Validset']\n",
    "\n",
    "train_ds = SequenceDataset(trainset, cell_type_dict)\n",
    "test_ds  = SequenceDataset(testset , cell_type_dict)\n",
    "valid_ds = SequenceDataset(validset, cell_type_dict)\n",
    "\n",
    "train_loader = DataLoader(train_ds , batch_size=16)\n",
    "test_loader  = DataLoader(test_ds  , batch_size=16)\n",
    "valid_loader = DataLoader(valid_ds , batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eeaab99-5126-49f0-939b-1925e022e9d2",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbc6a0d-df81-4d81-86e8-2d913c5dcca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "motifs_f, motifs_r, motif_names, motif_length = load_pwm_from_meme_c(\n",
    "    \"/cluster2/huanglab/liquan/motif/consensus_pwms.meme\", max_length=35\n",
    ")\n",
    "seed = 114514\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True  # 禁用cudnn非确定性算法\n",
    "torch.backends.cudnn.benchmark = False     # 关闭自动寻找最优卷积算法\n",
    "kernel_fwd  = torch.tensor(motifs_f,dtype=torch.float)\n",
    "kernel_rev  = torch.tensor(motifs_r,dtype=torch.float)\n",
    "d_in = None\n",
    "d_model = 512\n",
    "num_filters = 512\n",
    "\n",
    "model = eSCREEN(\n",
    "    kernel_fwd = kernel_fwd,kernel_rev = kernel_rev,d_model=d_model,\n",
    "    num_filters=num_filters,seq_length=500,celltype_num=32,lr=1e-5,device='cuda:1',\n",
    ")\n",
    "\n",
    "with open('/cluster2/huanglab/liquan/data/eSCREEN/ANLYSIS/code/StripedHyena/torch_logs/MIX_mix_celltype.dict','r') as file:\n",
    "    cell_type_dict = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f23a51-9a37-401c-aa4c-e97c345ed3a2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "model.fit(train_loader,test_loader,epochs=10,lr=1e-4,check_step=500,earlystop=20,device='cuda:0',save_name='./K562_model')\n",
    "model.load_state_dict( torch.load('./K562_model.best.pt') )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6e5f50-46ea-42f9-9e90-583948cc2be3",
   "metadata": {},
   "source": [
    "## Prediction & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdb07e51-2f98-49cc-8927-6a52e4d8630f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230/230 [00:07<00:00, 30.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6879 0.7076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "p,y = model.predict(valid_loader,device='cuda:0',verbose=True,with_true=True)\n",
    "print( round(spearmanr(p,y)[0],4),round(pearsonr(p,y)[0],4) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0bcc73c4-8700-4559-9d65-0b4ba532b468",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.8972\n",
      "MCC: 0.6559\n",
      "F1 Score: 0.8294\n",
      "Accuracy: 0.8279\n",
      "Recall: 0.8243\n",
      "Precision: 0.8346\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import matthews_corrcoef, f1_score, accuracy_score, recall_score, precision_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "predictions = p;labels = y\n",
    "predicted_labels = [1 if p >= 0.5 else 0 for p in predictions]\n",
    "\n",
    "# 计算指标\n",
    "auc_val = auc(roc_curve(labels, predictions)[0],roc_curve(labels, predictions)[1])\n",
    "mcc = matthews_corrcoef(labels, predicted_labels)\n",
    "f1 = f1_score(labels, predicted_labels)\n",
    "accuracy = accuracy_score(labels, predicted_labels)\n",
    "recall = recall_score(labels, predicted_labels)\n",
    "precision = precision_score(labels, predicted_labels)\n",
    "\n",
    "# 输出结果\n",
    "print(f\"AUC: {auc_val:.4f}\")\n",
    "print(f\"MCC: {mcc:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(4,2))\n",
    "plt.bar([1,2,3,4,5,6],[auc_val,mcc,f1,accuracy,recall,precision])\n",
    "plt.ylim([0,1])\n",
    "plt.xticks([1,2,3,4,5,6],[\"AUC\",\"MCC\",\"F1 Score\",\"Accuracy\",\"Recall\",\"Precision\"],rotation=-30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d49436c-4c9c-4941-8200-55bea59309eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "escreen",
   "language": "python",
   "name": "escreen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
